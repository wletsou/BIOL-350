[["index.html", "BIOL 350: Bioinformatics Chapter 1 Introduction", " BIOL 350: Bioinformatics William Letsou April 2024 Chapter 1 Introduction Welcome to BIOL-350 at New York Tech!  For this set of lectures, follow along with the slides here.  Each chapter describes the theory and practice of the step in an analysis pipeline for you to conduct your own genetic association study. "],["Week1.html", "Chapter 2 Principal Components Analysis 2.1 Pricipal components analysis: theory 2.2 Principal components analysis: practice 2.3 References", " Chapter 2 Principal Components Analysis This week we’ll see how individuals can be separated by genetic ancestry using principal components analysis.  We’ll practice applying PCA on a subset of the 1KGP data [1]. 2.1 Pricipal components analysis: theory The populations in our dataset can be separated into clusters based on their genotypes.  The inferred groups help control for confounding due to ancestry, and are also more reliable than self-reported race in association studies [2].  To see how it works, suppose \\(\\mathbf{X}\\) is an \\(n\\times m\\) (standardized) genotype matrix with individuals down the rows and SNPs across the columns.  Principal components analysis (PCA) says we can find an \\(m\\times n\\) matrix \\(\\mathbf{V}\\), a diagonal \\(n\\times n\\) matrix \\(\\mathbf{\\Sigma}\\), and an \\(n\\times n\\) matrix \\(\\mathbf{U}\\) satisfying \\[\\begin{equation} \\mathbf{X}=\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^T. \\tag{2.1} \\end{equation}\\]If we think of \\(\\mathbf{V}\\) as the the (standardized) SNP genotypes of an “ideal” person of a certain ancestry, then \\[\\begin{equation} x_{j\\cdot} v_{\\cdot i}=u_{ji}\\lambda_{ii} \\tag{2.2} \\end{equation}\\]represents the amount of idealized person \\(i\\) in actual person \\(j\\), up to some proportionality constant \\(\\lambda_{ii}\\) that depends on the ancestry.  Then rows \\(j\\) of \\(\\mathbf{U}\\) are the ancestries of person \\(j\\), and columns \\(i\\) of \\(\\mathbf{U}\\) are the ancestries of each individual on ancestry \\(i\\).  It is important to remember that these “idealized” ancestries do not necessarily correspond with our preconceived notions of ancestry, so we cannot interpret them as “European,” “African,” or “Asian,” say.  If we rearrange Eq. (2.1) and use the fact that the columns of \\(\\mathbf{U}\\) and \\(\\mathbf{V}\\) are orthonormal, we can find that \\[\\begin{equation} \\mathbf{X}\\mathbf{X}^T\\mathbf{U}=\\mathbf{U}\\mathbf{\\Sigma}^2, \\tag{2.3} \\end{equation}\\]meaning that the columns of \\(\\mathbf{U}\\) are the eigenvectors of the matrix \\[\\begin{equation} \\frac{1}{m}\\mathbf{X}\\mathbf{X}^T \\tag{2.4} \\end{equation}\\] whose \\(\\left(i,j\\right)\\) entry is the genetic correlation between individuals \\(i\\) and \\(j\\), sometimes known as the genomic relationship matrix or GRM.  PCA works by finding the first several eigenvectors of the GRM and plotting each individual’s ancestry along each orthogonal vector in a rectangular grid.  Clusters of individuals in this grid represent distinct ancestry groups. PCA is used in many field besides genetics, and a good tutorial can be found here [3]. 2.2 Principal components analysis: practice We’ll need to use several Biocondunctor packages in the following analyses.  If you have not used Biocondunctor before, run: install.packages(&quot;BiocManager&quot;,repos = &quot;http://cran.us.r-project.org&quot;) Then to install a package from Biocondunctor for the first time, use the BiocManager::installs() command with the name of your package in quotes.  For example: BiocManager::install(&quot;SNPRelate&quot;) 2.2.1 Importing the data To do PCA in R, we’ll need to load the libraries SNPRelate and SeqArray: library(SNPRelate) library(SeqArray) Download the chr1 vcf file containing just the CEU, YRI, and CHB populations.  Once you have the file, store its name as a variable: vcf &lt;- &quot;path/to/file.vcf.gz&quot; Now we’ll convert from vcf format to gds format, retaining the base filename and changing the vcf.gz extension to gds.  (This may take a minute to complete.)  Then we’ll import the gds file as a gds object: seqVCF2GDS(vcf.fn = vcf,&quot;path/to/file.gds&quot;) # convert vcf to gds with a new file name genofile &lt;- seqOpen(&quot;path/to/file.gds&quot;) # import the gds object You can can see the various fields under genofile by printing it.  To access the data in one of the fields, do seqGetData(genofile,&quot;sample.id&quot;) # view the sample ids where the name of the field is enclosed in quotes.  Other functions for manipulating and view gds files are contained in the SeqArray package [4, 5]. 2.2.2 Running PCA To run PCA in R using the SNPRelate package [4], simply do pca &lt;- snpgdsPCA(genofile) # runs PCA to create an objects with 32 eignevectors of the GRM.  Make a data frame of the first several eigenvectors along with subject ids: df.pca &lt;- data.frame(sample = pca$sample.id,EV1 = pca$eigenvect[,1],EV2 = pca$eigenvect[,2],EV3 = pca$eigenvect[,3],stringsAsFactors = FALSE) We’ll plot individuals along EV1, EV2, and EV3 in several two-dimensional projections.  But we’ll want to see how the clustering done by PCA corresponds to individuals’ self-reported race; for that we’ll need another column in our data frame. 2.2.3 Getting the population labels The indivs file contains each subject id along with its 1KGP population group.  Let’s import it now: indivs &lt;- read.table(&quot;path/to/CHB+YRI+CEU.txt&quot;,header = FALSE) colnames(indivs) &lt;- c(&quot;id&quot;,&quot;pop&quot;) The second field of this table is pop, an assignment to each id of one of three 1KG population groups.  We want to match the right ID in indivs to the right ID in df.pca so that we can color our PCA plots by population.  If the tables are in the same order, matching will be easy, but it not, we have to use the match(x,y) function, which finds the positions in y corresponding to the same items in x.  Thus we can make a new column pop in df.pca with the corresponding pop values from indivs by df.pca$pop[match(indivs$id,df.pca$sample)] &lt;- indivs$pop # find the population group of each individual in df.pca 2.2.4 Plotting Now that we have a column of population labels, we can make a scatter plot colored by treating the pop column as vector of factors; we can get the unique values of a factor vector by applying the function levels() to it.  A plot of the second principal component vs. the first can then be generated by par(mar = c(5.1,5.1,4.1,2.1) ) plot(df.pca$EV1,df.pca$EV2,pch = 19,col = factor(df.pca$pop),xlab = &quot;PC1&quot;,ylab = &quot;PC2&quot;,cex.lab = 1.5,cex.axis = 1.5,cex.main = 1.5) # plot of PC2 vs. PC1 legend(&quot;topright&quot;,legend = levels(factor(df.pca$pop)),bty = &quot;n&quot;,pch = 19,col = factor(levels(factor(df.pca$pop))),pt.cex = 1,cex = 1.5,x.intersp = 0.2) # with a legend Move the legend around if it covers any points, and make similar plots for the other two comparisons between the first three PCs. Finally, close the connection to the gds file when you are done: seqClose(genofile) 2.2.5 To turn in: Make three (nicely formatted) plots of: PC2 vs. PC1 PC3 vs. PC1 PC3 vs. PC2 For each plot, discuss: Whether the populations appear to be well separated in PCA space What the gradients of the different PCs represent, that is, what axis of variation each PC appears to explain How to subset your df.pca data frame to isolate individuals of each population (i.e., provide code) 2.3 References References "],["Week2.html", "Chapter 3 Kinship Analysis 3.1 Kinship: theory 3.2 Kinship: practice 3.3 References", " Chapter 3 Kinship Analysis 3.1 Kinship: theory Kinship can be defined as the expected fraction of alleles that two individuals got from the same ancestor(s).  We say that two individuals share an allele of a SNP identical-by-descent or IBD if they inherited the same copy of the allele from a common ancestor.  IBD-sharing is different from simply carrying the same allele of a gene (known as identical-by-state or IBS-sharing), which unrelated individuals may do if the allele is common enough in the population.  The degree \\(R\\) of relationship may be defined as the effective number of meioses separating the relatives through the equation \\[\\begin{equation} \\frac{1}{2^R}=\\frac{1}{2^{R_1}}+\\frac{1}{2^{R_2}}, \\tag{3.1} \\end{equation}\\] in which \\(R_i\\) is the number of meioses separating the relatives through the first relative’s \\(i\\)th parent.  For example, sibs are connected by two meioses through two parents, while a parent and child are connected by one meiosis through one parent: both relationships are degree-1. The probability that two relatives share an allele IBD is \\(\\frac{1}{2^R}\\), as there is a \\(\\frac{1}{2}\\) probability that an allele is passed on in any meiosis, and \\(R\\) is the effective number of meioses or steps between the relatives.  If \\(2\\times\\frac{1}{2^R}\\) is the expected number of alleles shared IBD at any given locus, then the fraction of the genome shared by any two relatives is \\[\\begin{equation} r=\\frac{2\\times\\frac{1}{2^R}}{2}=\\frac{1}{2^R}. \\tag{3.2} \\end{equation}\\] However, genomic sharing can be realized in different ways depending on the probabilities \\(\\pi_0\\), \\(\\pi_1\\), and \\(\\pi_2\\) that individuals share zero, one, or two copies IBD at a locus.  The probability that the relatives inherit both both copies IBD, viz., \\[\\begin{equation} \\pi_2=P\\left(\\text{share 2 IBD}\\right)=2^2\\frac{1}{2^{R_1}2^{R_2}}, \\tag{3.3} \\end{equation}\\]is simply the product of the probabilities of sharing through both parents.  The probability of sharing exactly one allele IBD, viz., \\[\\begin{equation} \\pi_1=P\\left(\\text{share 1 IBD}\\right)=2\\left(\\frac{1}{2^{R_1}}+\\frac{1}{2^{R_2}}\\right)-2^3\\frac{1}{2^{R_1}2^{R_2}}, \\tag{3.4} \\end{equation}\\]is the got by finding the probability \\(2\\left(\\frac{1}{2^{R_1}}+\\frac{1}{2^{R_2}}\\right)-2^2\\frac{1}{2^{R_1}2^{R_2}}\\) of sharing at least one allele IBD less the probability \\(\\pi_2\\) of sharing two.  Finally, the probability of sharing at least zero alleles IBD, viz., \\[\\begin{equation} \\pi_0=P\\left(\\text{share 0 IBD}\\right)=1-2\\frac{1}{2^{R_1}}-2\\frac{1}{2^{R_2}}+2^2\\frac{1}{2^{R_1}2^{R_2}}, \\tag{3.5} \\end{equation}\\]is got by subtracting the probability \\(\\pi_1+\\pi_2\\) of sharing at least one allele IBD from 1.  The coefficients account for the fact that there are \\(2\\) alleles at each locus, and \\(2^2\\) that can be shared. From (3.3)–(3.5), the fraction of the genome shared IBD is \\[\\begin{equation} r=\\frac{2\\pi_2+1\\pi_1}{2}=\\frac{1}{2^{R_1}}+\\frac{1}{2^{R_2}}=\\frac{1}{2^R}. \\tag{3.4} \\end{equation}\\]But the same value of \\(r\\) can obtain from different values of \\(\\pi_1\\) and \\(\\pi_2\\).  For example, full sibs have a 25% probability of sharing two alleles and a 50% chance of sharing one allele at a locus, for a total fraction \\(r=0.5\\) shared.  But a parent and child have 0% chance of sharing two alleles and a 100% chance of sharing one, also giving \\(r=0.5\\).  Thus, your parent does is not equal your sibling, despite the fact of your sharing equal amounts of your genome with each of them.  Put another way, parents cannot pass on their genotypes to their offspring. 3.1.1 KING KING [6] computes both the probability \\(\\pi_0\\) that two relatives share 0 alleles IBD as well as the coefficient of relatedness \\(\\phi=\\frac{r}{2}\\), defined as the probability that two alleles taken one from each relative are IBD at a locus (the maximum probability is \\(\\frac{1}{2}\\) because there is a 50% chance that the alleles chosen come from different parents).  The idea is to compare the counts \\(X\\) and \\(Y\\) of the alternative alleles which two individuals each have at a genetic locus.  If the pair are from a single ancestral population, the expected values and variances of the allele counts are \\(\\mathbb{E}\\left(X\\right)=\\mathbb{E}\\left(Y\\right)=2p\\) and \\(\\sigma_X^2=\\mathbb{E}\\left(X^2\\right)-\\mathbb{E}\\left(X\\right)^2=\\mathbb{E}\\left(Y^2\\right)-\\mathbb{E}\\left(Y\\right)^2=2p\\left(1-p\\right)\\).  Thus the expected value of the difference \\(\\mathbb{E}\\left(\\left(X-Y\\right)^2\\right)=\\mathbb{E}\\left(X^2\\right)+\\mathbb{E}\\left(Y^2\\right)-2\\mathbb{E}\\left(XY\\right)\\) is \\[\\begin{equation}\\frac{\\mathbb{E}\\left(\\left(X-Y\\right)^2\\right)}{\\sigma_X^2+\\sigma_Y^2}=1-\\frac{\\sigma_{XY}}{\\sigma_X\\sigma_Y}=1-r, \\tag{3.6} \\end{equation}\\]where \\(\\sigma_{XY}=\\mathbb{E}\\left(XY\\right)-\\mathbb{E}\\left(X\\right)\\mathbb{E}\\left(Y\\right)\\) is the covariance of the genotype counts and \\(r_{ij}=2\\varphi_{ij}\\) is the genetic correlation between individuals \\(i\\) and \\(j\\); the latter can be interpreted as the amount of the genome shared IBD. KING estimates \\(\\varphi\\) from Eq. (3.6) by counting the number \\(N\\) of loci at which two individuals are heterozygous \\(Aa,Aa\\) or opposite homozygous \\(AA,aa\\), as well as the total number of alleles at which each individual is heterozygous \\(Aa\\): \\[\\begin{equation} \\hat{\\varphi_{ij}}=\\frac{N_{Aa,Aa}-2N_{AA,aa}}{N_{Aa}^{\\left(i\\right)}+N_{Aa}^{\\left(j\\right)}}. \\tag{3.7} \\end{equation}\\]From (3.7) it can be seen that shared heterozygous sites increase the estimated relatedness, and that unshared homozygous sites decrease relatedness.  Eq. (3.7) is called a “robust” estimator because it measures relatedness in a purely pairwise fashion: it does not rely on population estimates of allele frequencies.  However, if the individuals are not of the same genetic background, the allele frequency \\(p\\) is not well-defined and Eq. (3.6) does not hold, leading to negative estimates of \\(\\varphi\\); this feature is not necessarily a problem, as it helps us to distinguish different ancestries within a single population. 3.1.2 PC-AiR KING provides an estimate of relatedness.  But as cryptic relatedness can skew ancestry estimates determined by PCA, we should use kinship to correct PCA.  This is where principal components analysis in related samples, or PC-AiR [7] comes in handy. PC-AiR identifies a subset of \\(\\mathcal{U}\\) of individuals who are unrelated to each other (via negative KING kinship estimates), but maximally related to individuals in a remaining set \\(\\mathcal{R}\\). Recalling the math in Week 1, the matrix \\[\\begin{equation} \\frac{1}{m}\\mathbf{W}=\\mathbf{X}^T\\mathbf{U}=\\mathbf{V}\\mathbf{\\Sigma}, \\tag{3.8} \\end{equation}\\]so that \\(\\frac{1}{m}w_{jk}\\lambda_{kk}^{-1}=x_{ij}u_{ik}\\lambda_{kk}^{-1}=v_{jk}\\) is the genotype at SNP \\(k\\) in ancestry \\(j\\) inferred from subjects’ genotypes \\(\\mathbb{X}\\) who are in subset \\(\\mathcal{U}\\).  Then if we have an \\(m\\times n_u\\) genotype matrix \\(\\mathbf{X}&#39;\\) of individuals in the subset \\(\\mathcal{R}\\), we can “apply” \\(\\mathbf{W}\\) to get an estimate of the “ancestry-corrected” PCs by: \\[\\begin{equation} \\frac{1}{m}\\mathbf{X}&#39;\\mathbf{W}\\mathbf{\\Sigma}^{-1}=\\mathbf{X}&#39;\\mathbf{V}. \\tag{3.9} \\end{equation}\\]Eq. (3.9) is the matrix \\(x&#39;_{i\\cdot}v_{\\cdot j}\\) of similarities between subjects \\(i\\) in set \\(\\mathcal{R}\\) and ancestry \\(j\\).  In this way, we have estimated genotype principal components for all individuals (i.e., those in \\(\\mathcal{U}\\) and \\(\\mathcal{R}\\)) without the problem confounding due to cryptic relatedness. 3.1.3 PC-Relate Once we have ancestry-corrected principal components for all individuals, we can obtain “corrected” expected genotypes \\(\\mathbb{E}\\left(X_{ik}\\right)=2p_{ik}\\) of SNPs \\(k\\) for populations of admixed individuals \\(i\\) using a method known as PC-Relate [8].  Because in populations with both shared genetic ancestry and cryptic relatedness, we can use the PC estimates \\(v_{kj}\\) of the allele frequencies in each population \\(j\\) to express the scaled genotypes \\(x_{ij}=\\frac{g_{ik}-2p_k}{2p_k\\left(1-p_k\\right)}\\) as \\[\\begin{equation} \\mathbb{E}\\left(x_{ik}\\mid u_{ij}\\right)=u_{ij}\\lambda_{jj}v_{kj}, \\tag{3.9} \\end{equation}\\]or, in terms of the measured genotypes: \\[\\begin{equation} \\mathbb{E}\\left(g_{ik}\\mid u_{ij}\\right)=2p_k+u_{ij}\\lambda_{jj}v_{kj}\\cdot 2p_k\\left(1-p_k\\right), \\tag{3.10} \\end{equation}\\]in which \\(p_k\\) is the allele frequency estimated from the entire sample.  Eq. (3.10) says that if we make a graph of each individual’s genotype \\(g_{ik}=0,1,2\\) at SNP \\(k\\) vs. the (scaled) of the amount the individual’s population-\\(j\\) genetic ancestry, the slope \\(\\lambda_{jj}v_{kj}2p_k\\left(1-p_k\\right)\\) should be the expected allele frequency in population \\(j\\).  In practice, the slopes are obtained from linear regression of the observed genotypes on genetic PCs, and the updated expected allele frequencies \\(\\mathbb{E}\\left(g_{ik}\\mid u_{ij}\\right)=2p_{ik}\\) of SNPs \\(k\\) for individuals \\(i\\) are found by the corresponding value on the best-fit hyperplane, given individual \\(i\\)’s genetic ancestry \\(u_{ij}\\).  We can then obtain a new genetic relationship matrix: \\[\\begin{equation} 2\\hat{\\varphi}_{ij}=\\frac{\\sum_k\\left(g_{ik}-2p_{ik}\\right)\\left(g_{jk}-2p_{jk}\\right)}{2\\sqrt{p_{ik}\\left(1-p_{ik}\\right)p_{jk}\\left(1-p_{jk}\\right)}}. \\tag{3.11} \\end{equation}\\]This new GRM will be used in Week 3 when we attempt to fit a linear mixed model for the effect of genotype on disease risk; for now we will use it to make an updated table of the relationship between individuals. 3.2 Kinship: practice 3.2.1 Importing data Now we’ll try kinship analysis for ourselves using a simulated GWAS dataset.  This dataset was created using the program bioGWAS [9], which uses other programs to simulate haplotypes [10] and phenotypes [11] based on a set of input variants previously associated with breast cancer [12] and made available by the MRC Interactive Epidemiology Unit’s Open GWAS Project [13].  This particular vcf file contains 1000 chromosome 10 genotypes at 345,130 variants (304,770 of which are SNPs) generated from 263 1KGP females of European origin.  Download and unzip the file: gunzip EUR_BCa.vcf.gz and move it to your desired location.  The unzipped file is readable in plain text format, although it is very big. Next load the following R packages: library(gdsfmt) library(GWASTools) library(SNPRelate) library(GENESIS) Our first task will be to import the vcf file and convert it to gds format.  First specify the directory in which you saved your EUR_BCa.vcf: directory &lt;- &quot;path/to/folder # fill in the appropriate path to downloads folder   Then define two file names: vcf.fn &lt;- sprintf(&quot;%s/EUR_BCa.vcf&quot;,directory) # vcf file name (exists already) gds.fn &lt;- sprintf(&quot;%s/EUR_BCa.gds&quot;,directory) # gds file name (about to be created) Next perform the conversion and importation into R: snpgdsVCF2GDS(vcf.fn,gds.fn) # create gds file from vcf genofile &lt;- snpgdsOpen(gds.fn,readonly = FALSE) # import gds object The GDS format is an efficient representation of vcf files which does not require that the entire file be loaded into memory at once [4].  By typing genofile you can see all the fields under your gds object.  To access one of these nodes, type index.gdsn(genofile,&quot;sample.id&quot;) # vector of sample names or read.gdsn(index.gdsn(genofile,&quot;genotype&quot;),start = c(1,1), count = c(5,5)) # read a 5 x 5 matrix of SNP genotypes This second line uses the start and count options to extract a range of data from the 1000 × 304,770 matrix of genotypes.  If you have a vector of phenotypes (as will will in Week 3), you can add it as a node in your gds: add.gdsn(genofile,&quot;phenotype&quot;,val = fam$Phenotype) # add vector of phenotypes from a table 3.2.2 PCA and LD-pruning For now, we can run PCA on the genotype matrix by simply typing pca &lt;- snpgdsPCA(genofile) # principal components analysis We do not even have to specify the genotype node of genofile.  Make a plot of the first few PCs as we did in Week 1. There are 304770 SNPs in this dataset; many are in LD with their neighbors.  To find a set of independent SNPs, which are not in LD (\\(r&gt;0.10\\)) inside a sliding window of size ten million bp, we run: set.seed(566) # set random seed to initiate pruning process snpset &lt;- snpgdsLDpruning(genofile,method = &quot;corr&quot;, slide.max.bp = 10e6,ld.threshold = sqrt(0.1), verbose = FALSE) # LD prining pruned &lt;- unlist(snpset, use.names = FALSE) # set of independent SNPs 3.2.3 KING IBD and kinship calculation With our set of pruned SNPs, we can run KING to compute the pairwise kinship coefficient (\\(\\varphi_{ij}=\\frac{1}{2}r_{ij}\\)).  We will extract the kinship matrix from the created ibd object and rename the rows and columns with the ids of the samples: ibd &lt;- snpgdsIBDKING(genofile,snp.id = pruned) # KING kinship estimation colnames(ibd$kinship) &lt;- ibd$sample.id rownames(ibd$kinship) &lt;- ibd$sample.id Print a 10 × 10 sample of the kinship matrix using: ibd$kinship[1:10,1:10] Do the results make sense?  Hint: what should an individual’s kinship be with itself? Finally, we will make a plot of kinship vs. the fraction of the genome shared IBS = 0.  This will take a minute or two to plot, because the data consist of all pairwise observations. par(mar = c(5.1,5.1,4.1,2.1) ) # left default plus one plot(ibd$IBS0,ibd$kinship,ylab = &quot;Kinship coeffecient&quot;,xlab = &quot;IBS0&quot;,main = &quot;KING relatedness estimation&quot;, ylim = c(0,1),pch = 19,cex.lab = 1.5,cex.axis = 1.5,cex.main = 1.5) # plot kinship coefficient vs. proportion of SNPs not shared IBS You should notice that related individuals have a low fraction of IBS = 0, whereas unrelated individuals have a larger proportion.  The graph should be approximately linear, but with discontinuities as the relationsips become closer.  There should not be many close relatives in this dataset.  What, for example, is the largest inferred value of \\(\\varphi\\)? In addition, if you remove the ylim = c(0,1) option, you will see a large cluster of negative kinship coefficients.  These values are expected if the (simulated) individuals are from different genetic backgrounds. Before proceding to the next step, close your gds file: closefn.gds(genofile) 3.2.4 PC-AiR The PC-AiR method is part of the GENESIS package, which imports gds files through: geno &lt;- GdsGenotypeReader(sprintf(&quot;%s/EUR_BCa.gds&quot;,directory)) # import the gds file you created above genoData &lt;- GenotypeData(geno) and converts the objects to GenotypeData format [14]. Now we can run PC-Air.  It is important to include the kinship estimates we got from KING, as well as the list of pruned SNPs.  These values will help PC-AiR determine a set \\(\\mathcal{U}\\) of ancestry-representative individuals and their principal components, which will then imputed into the remaining subset \\(\\mathcal{R}\\) of individuals: mypcair &lt;- pcair(genoData,kinobj = ibd$kinship,divobj = ibd$kinship,snp.include = pruned) # genotype principal components based on a subset of unrelated individuals Next we can make a plot of the first few PCs using: par(mar = c(5.1,5.1,4.1,2.1) ) # left default plus one plot(mypcair,vx = 1, vy = 2) # plot of PC2 vs PC1 Change the values of vx and vy to change which PCs are plotted. 3.2.5 PC-Relate With our improved PCA results from PC-AiR, we will next update the GRM using individual-specific expected genotype counts \\(2p_{ik}\\).  First we need to create an interator that evaluates blocks of SNPs one at a time. genoData.iterator &lt;- GenotypeBlockIterator(genoData,snpInclude = pruned) From our pruned set of SNPs, you should have only one block. Next we can run PC-Relate to update the kinship coefficients.  From the PCs determined from PC-Air, we can get the new GRM by running: mypcrel &lt;- pcrelate(genoData.iterator,pcs = mypcair$vectors[,1:2],training.set = mypcair$unrels) # kinship based on unrelated individuals The output object contains a field called kinBtwn which contains subfields k0 and kin corresponding to the fraction of the genome shared IBD = 0 and the kinship between each pair of individuals.  Make a plot of these values, similar to KING’s, using: par(mar = c(5.1,5.1,4.1,2.1) ) # left default plus one plot(mypcrel$kinBtwn$k0,mypcrel$kinBtwn$kin,xlab = &quot;IBD0 proportion&quot;,ylab = &quot;Kinship coefficient&quot;,main = &quot;PC-relate relatedness estimation&quot;,pch = 19,cex.axis = 1.5,cex.lab = 1.5,cex.main = 1.5) # kinship vs. IBD0 Finally, we convert the results of pcrelate to a GRM: myGRM &lt;- pcrelateToMatrix(mypcrel,scaleKin = 2) # genomic relationship matrix, multiplying each phi by 2 We scale by a factor of 2 in this code so that each kinship is multiplied by 2: then the entries of the GRM will represent the fraction of the genome shared IBD.  Extract a 10 × 10 subset of this matrix to see if the results make sense, and how they compare to KING’s kinship matrix computed above: myGRM[1:10,1:10] Now you can close the file: close(genoData) Save all your steps from today’s analysis–we will be repeating them in Week 3 when we perform the association study. 3.2.6 To turn in: Generate the following plots generated using the different methods, and comment on how they compare. PCA plots of a) PC1 vs. PC2, b) PC1 vs. PC3, and c) PC2 vs. PC3 generated by both snpgdsPCA and PC-AiR. Plots of kinship vs. IBD0 fraction generated by both KING and PC-Relate. 10 × 10 samples of the GRM generated by both KING and PC-Relate. 3.3 References "],["Week3.html", "Chapter 4 Association testing 4.1 Statistics 4.2 Practice 4.3 References", " Chapter 4 Association testing In this assignment, we will use the kinship matrix and principal components derived from our dataset to fit a generalized linear model using the method of restricted maximum likelihood [@] to find the association of a polymorphism with the disease phenotype. 4.1 Statistics 4.1.1 The odds ratio The logic of any genetic association study is to see if an allele is enriched in subjects affected with disease.  In other words, we want to see if the allele is associated with disease.  We do this by collecting may individuals with disease and a similar number of healthy controls from the general popuation.  An individual’s risk is its probability \\(P\\left(\\text{Disease}\\mid\\text{Allele}\\right)\\) of developing disease over its lifetime, and the relative risk or RR is the ratio of the risk to carriers to the risk to non-carriers of the allele.  However, the RR is difficult to measure prosepctively because it involves waiting a long time for a potentially smaller number of cases to develop.  If we retrospectively select cases that have already developed and match them with healthy controls, we can instead calculate an individual’s probability \\(P\\left(\\text{Allele}\\mid\\text{Disease}\\right)\\) of carrying the allele conditioned on its disease status.  Related to the probability \\(p\\) of an event is the odds \\(\\frac{p}{1-p}\\) of the the event, and it turns out that the odds ratio \\[\\begin{equation} \\text{OR}=\\frac{\\frac{P\\left(\\text{Allele}\\mid\\text{Cases}\\right)}{1-P\\left(\\text{Allele}\\mid\\text{Cases}\\right)}}{\\frac{P\\left(\\text{Allele}\\mid\\text{Controls}\\right)}{1-P\\left(\\text{Allele}\\mid\\text{Controls}\\right)}} \\tag{4.1} \\end{equation}\\]is invariant to whether we collect subjects prospectively or retrospectively.  Hence we use the OR as a convenient measure of the effect of an allele on disease risk in case-control studies.  However, the crude measure (4.1) cannot be adjusted for other factors like sex, age, and genetic ancestry which may also have an effect on disease risk.  For this type of analysis, we need logistic regression. 4.1.2 The logistic model of disease risk Normally we test the association between two variables using linear regression, but doing so requires that both the dependent and independent variables be continuous.  In genetic association studies, neither the outcome (disease) nor the predictor (number of risk alleles) is continuous.  However, an individual’s unobserved propensity \\(p\\) is a continuous variable that ranges between 0 and 1; furthermore, the individual’s log-odds \\(\\log{\\frac{p}{1-p}}\\) of disease is a continuous value that ranges between \\(-\\infty\\) and \\(+\\infty\\).  Thus if we assume that the log-odds of disease can be represented by the equation \\[\\begin{equation} \\log{\\frac{p}{1-p}}=\\beta_0+\\beta_1X_1, \\tag{4.2} \\end{equation}\\] where \\(X_1\\) is number of risk alleles and \\(\\beta_1\\) is the log-odds-ratio, then we can in principle fit a line and estimate its slope.  This slope \\(\\beta_1\\) would then be interpretted as the multiplicative increase in the log-odds of disease. Now, since we cannot observe \\(p_i\\) for each subject \\(i\\), we cannot actually fit (4.2) using linear regression.  We can, however, use the concept of maximum likelihood.  In statistics, the likelihood of a disease model like (4.2) is the probability of the data being generated by the model, or \\[\\begin{equation} \\mathcal{L}\\left(\\text{Model}\\mid\\text{Data}\\right)=P\\left(\\text{Data}\\mid\\text{Model}\\right). \\tag{4.3} \\end{equation}\\]Here the model is the set of parameters \\(\\beta_0,\\beta_1\\) required to predict disease risk, and we can find estimates for the parameters by maximizing (4.3), i.e., by finding the model most consistent with the data.  Furthermore, if the likelihood function has approximately the shape of a normal distribution, then we can estimate the statistical significance of our estimates by computing their standard error, got from the curvature or second derivative of \\(\\mathcal{L}\\) near the \\(\\beta\\) which maximize it. The binomial distribution is a good approximation to the normal distribution, so if we model the likelihood of the observed data as \\[\\begin{equation} \\mathcal{L}=\\prod_ip_i^{y_i}\\left(1-p_i\\right)^{1-y_i}, \\tag{4.4} \\end{equation}\\] where \\(y_i=0,1\\) is an indicator of disease status, then the log-likelihood is \\[\\begin{align} \\ell&amp;=\\sum_iy_i\\log{p_i}+\\left(1-y_i\\right)\\log{\\left(1-p_i\\right)}\\\\&amp;=\\sum_iy_i\\log{\\frac{p_i}{1-p_i}}+\\log{\\left(1-p_i\\right)} \\tag{4.5} \\end{align}\\]using (4.2) \\[\\begin{equation} \\ell=\\sum_iy_i\\left(\\beta_0+\\beta_1X_{i1}\\right)-\\log{\\left(1+e^{\\beta_0+\\beta_1X_{i1}}\\right)}. \\tag{4.6} \\end{equation}\\]Eq. (4.6) is a function of the parameter \\(\\beta_1\\).  Thus we can find the maximum-likelihood estimate \\(\\hat{\\beta_1}\\) of \\(\\beta_1\\) by solving \\(\\frac{\\partial \\ell}{\\partial \\beta_1}\\bigr\\rvert_{\\beta_1=\\hat{\\beta_1}}\\) for \\(\\hat{\\beta_1}\\) and getting its standard error \\(\\frac{-1}{\\frac{\\partial^2\\ell}{\\partial \\beta_1^2}\\bigr\\rvert_{\\beta_1=\\hat{\\beta_1}}}\\) by evaluating the curvature of the log-likelihood at the best estimate of \\(\\beta_1\\).  From these we can also get an estimate of the statistical significance. 4.1.2.1 Simulating phenotypes The PhenotypeSimulator package [11] used to generate the phenotype data used in this assignment generates a vector \\(\\theta\\) of log-odds for each individual based on its genotype, given an input list of risk SNPs.  To go from the log-odds scale scale to the binary disease scale, we can rearrange the equation \\(\\log\\frac{p}{1-p}=\\theta\\) to generate a vector \\[\\begin{equation} \\mathbb{P}\\left(\\text{Disease}\\mid \\theta\\right)=\\frac{e^{\\theta}}{1+e^{\\theta}} \\tag{4.7} \\end{equation}\\]of disease probabilities.  In a balanced case-control study, the probability of disease should be approximately 50%, corresponding to a mean log-odds of \\(\\overline{\\theta}=0\\).  If this condition does not obtain, we can recenter the data so that \\[\\begin{equation} \\mathbb{P}\\left(\\text{Disease}\\mid \\theta\\right)=\\frac{e^{\\theta -\\overline{\\theta}}}{1+e^{\\theta-\\overline{\\theta}}}. \\tag{4.8} \\end{equation}\\]This is always possible (in simulated data) because the intercept term \\(\\beta_0\\) in Eq. (4.2) can be shifted without changing the odds ratio \\(\\beta_1\\).  Disease phenotype can then be generated by drawing \\(N\\) random numbers \\(t_i\\) uniformly from the interval \\(\\left[0,1\\right]\\) and calling everyone a case whose probability \\(p_i\\geq t_i\\). 4.1.3 Linear mixed models In genome-wide association studies (GWAS) we want to estimate the odds ratio \\(e^{\\beta_1}\\) for each SNP to see if any SNPs are associated with disease.  However, there are millions of SNPs and only thousands of subjects, so we cannot fit all the parameters simultaneously.  Instead, one SNP effect \\(\\beta_1\\) is fit at a time, together with the other fixed covariate effects \\(\\beta_j\\) against a background of the composite, random effects of all the remaining SNPs together, so that our model has two components: \\[\\begin{equation} Y_i=\\log{\\frac{p_i}{1-p_i}}=\\sum_jX_{ij}\\beta_j+\\sum_jZ_{ij}u_j+\\varepsilon_i. \\tag{4.9} \\end{equation}\\]Here, \\(\\mathbf{Z}\\) is an \\(n\\times m\\) matrix of the (standardized) genotypes of \\(n\\) individuals at \\(m\\) SNPs and \\(u_j\\) is the effect of SNP \\(j\\) on the log-odds for individual \\(i\\).  The mixed-model framework assumes the random \\(u\\) come from a normal distribution with mean 0 and standard deviation \\(\\sigma\\), so that each variant has but a small effect on disease risk. Now, the variance of the log-odds \\(Y\\) about its mean \\(\\mathbf{X}\\beta\\) becomes \\[\\begin{align} \\left(Y-\\mathbf{X}\\beta\\right)\\left(Y-\\mathbf{X}\\beta\\right)^T&amp;=\\mathbf{Z}uu^T\\mathbf{Z}^T+\\varepsilon\\varepsilon^T\\\\ &amp;=\\left(\\mathbf{Z}\\mathbf{Z}^T+\\mathbf{I}\\right)\\sigma^2=\\mathbf{V}. \\tag{4.10} \\end{align}\\]Rearranging and differentiating with respect to \\(\\beta_k\\) obtains (with summation over \\(i\\), \\(j\\), and \\(l\\)) \\[\\begin{align} V_{li}^{-1}X_{ik}\\left(Y_l-X_{lj}\\beta_j\\right)^T+V_{il}^{-1}\\left(Y_l-X_{lj}\\beta_j\\right)X^T_{ki}&amp;=0\\\\\\left(X^T_{ki}V_{il}^{-1}Y_l-X^T_{ki}V_{il}^{-1}X_{lj}\\beta_j\\right)^T+\\left(X^T_{ki}V_{il}^{-1}Y_l-X^T_{ki}V_{il}^{-1}X_{lj}\\beta_j\\right)&amp;=0, \\tag{4.11} \\end{align}\\]since \\(\\mathbf{V}\\)–and hence \\(\\mathbf{V}^{-1}\\)–is a symmetric matrix.  And because the \\(k\\)th entry of a transposed vector is equal to the \\(k\\)th entry of the original vector, we get the maximum-likelihood solution \\[\\begin{equation} \\mathbf{X}^T\\left(\\mathbf{I}+\\mathbf{Z}\\mathbf{Z}^T\\right)^{-1}\\mathbf{X}\\hat{\\beta}=\\mathbf{X}^T\\left(\\mathbf{I}+\\mathbf{Z}\\mathbf{Z}^T\\right)^{-1}Y, \\tag{4.10} \\end{equation}\\]where \\(\\frac{1}{m}\\mathbf{Z}\\mathbf{Z}^T\\) is the genomic relationship matrix (GRM) we used to compute principle components in Week 1.  Thus we can estimatimate the fixed effects \\(\\beta\\)—including the SNP effect \\(\\beta_1\\)—and their standard errors without fitting the random effects of every other SNP simultaneously. 4.2 Practice 4.2.1 Get phenotype The first item we shall need when associating SNPs with disease risk is a phenotype file.  Download and save this file to the same location as your work from Week 2, along with the (unzipped) vcf file. Read in the phenotype file using fam &lt;- read.table(&quot;/path/to/file/EUR_BCa.fam&quot;,header = TRUE) This file is in PLINK format: its first column contains the family id of the individual in the second column; if the samples are unrelated, these two columns will be the same.  Similarly, the maternal and paternal ids are the ids of the mother and father of the sample, should they happen to be in the dataset.  Sex is left unspecified in this analysis. The most important column for our purposes is the Phenotype column, which contains a 1 for controls and a 2 for cases. Complete the steps KING, PC-AiR, and PC-Relate from Week 2.  At the end of this analysis, you should have the results mypcair and mypcrel of PC-AiR and PC-Relate, and updated GRM, an open GenotypeData object called genoData, and a GenotypeBlockIterator object called genoData.iterator.  This last will iterate over each of the pruned SNPs included in your model as you test each one for association with the disease phenotype. The first step is to create a dataframe for the null model, which regresses phenotype on genetic ancestry only: mydat &lt;- data.frame(scanID = mypcair$sample.id,pc1 = mypcair$vectors[,1],pc2 = mypcair$vectors[,2],pc3 = mypcair$vectors[,3],pc4 = mypcair$vectors[,4],pc5 = mypcair$vectors[,5],pc6 = mypcair$vectors[,6],pc7 = mypcair$vectors[,7],pc8 = mypcair$vectors[,8],pc9 = mypcair$vectors[,9],pc10 = mypcair$vectors[,10],pheno = fam$Phenotype - 1) # data frame of fixed effects Here we have included the first ten PCs.  The last column of this dataframe contains the phenotypes from the fam file; we have subtracted 1 from each entry so that 0 corresponds to controls, and 1 to cases. 4.2.2 Fitting the model Now we will fit the null model, i.e., Eq. (4.9) with just the fixed covariates \\(\\beta\\) and the random SNP effects \\(u\\); no SNP main effects have been fitted yet.  The computation is accomplished efficiently in the GENESIS package [14].  We need to specify the covariates as columns in dataframe mydat, and pass the GRM as a covariate matrix: scanAnnot &lt;- ScanAnnotationDataFrame(mydat) nullmod &lt;- fitNullModel(scanAnnot, outcome = &quot;pheno&quot;, covars = c(&quot;pc1&quot;,&quot;pc2&quot;,&quot;pc3&quot;,&quot;pc4&quot;,&quot;pc5&quot;,&quot;pc6&quot;,&quot;pc7&quot;,&quot;pc8&quot;,&quot;pc9&quot;,&quot;pc10&quot;), cov.mat = myGRM, family = &quot;binomial&quot;) # null model Now using our GenotypeDataIterator object, we can fit each SNP one-at-a-time: assoc &lt;- assocTestSingle(genoData.iterator,null.model = nullmod) # model including SNPs 4.2.3 Analyzing the results The dataframe assoc will contain a column Est of log-odds-ratios and another column Score.pval of p-values.  Make a Manhattan plot of the data using: par(mar = c(5.1,5.1,4.1,2.1) ) # left default plus one plot(assoc$pos,-log10(assoc$Score.pval),xlab = &quot;Position&quot;,ylab = &quot;-log10(p)&quot;,pch = 19,cex.axis = 1.5,cex.lab = 1.5,cex.main = 1.5) # Manhattan plot abline(h = 8 - log10(5),col = &#39;red&#39;,lty = 2) # genome-wide significance threshold close(genoData) Does any SNP appear to be associated with disease?  Is is genome-wide significant? To check that your answer makes sense, extract the data for the most-statistically-significant SNP: assoc[assoc$Score.pval &lt; 1e-5,,] # most-significant SNP(s) including its id and association statistics.  Then using the GWASTools getVariable on your genoData object, extract the name of this SNP: getVariable(genoData,&quot;snp.rs.id&quot;)[...] # insert variant.id To check that the SNP is indeed associated with disease, compute the allele frequency overall, and of the cases and controls separately (being sure to fill in … with the variant.id you found above): cases_genotypes &lt;- getVariable(genoData,&quot;genotype&quot;)[fam$Phenotype == 2,...] # genotypes of cases at the SNP controls_genotypes &lt;- getVariable(genoData,&quot;genotype&quot;)[fam$Phenotype == 1,...] # genotypes of controls at the SNP p_0 &lt;- sum(getVariable(genoData,&quot;genotype&quot;)[,...]) / 2 / length(getVariable(genoData,&quot;genotype&quot;)[,...]) # combined allele frequency p_cases &lt;- sum(cases_genotypes) / 2 / length(cases_genotypes) # cases allele frequency p_controls &lt;- sum(controls_genotypes) / 2 / length(controls_genotypes) # controls allele frequency Now you can compute a z-score, p-value, and (log) OR: z &lt;- (p_cases - p_controls) / sqrt(p_0 * (1 - p_0) * (1 / (length(cases_genotypes) - 1) + 1 / (length(controls_genotypes) - 1))) # z-score for allele frequency difference pnorm(-abs(z),lower.tail = TRUE) + pnorm(abs(z),lower.tail = FALSE) # two-sided p-value log( p_cases * (1 - p_controls) / (1 - p_cases) / p_controls) # log-OR How does your answer compare with the adjusted p-value found in the assoc table?  What might account for the difference? 4.2.4 To turn in {#Week3_practice_turnin}: A Manhattan plot of the SNPs in the region Information extracted from the assoc dataframe about the most-significant SNP Calculation of the crude logOR and p-value of the most-significant SNP 4.3 References References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
